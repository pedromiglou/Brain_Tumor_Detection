{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb7yyaPORH61"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "t4G7UWpmIHo0",
    "outputId": "c83cf3f6-6910-479c-e71b-e2725ae34c73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 17:32:56.686181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pedrod33/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-04-28 17:32:56.686222: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "%matplotlib inline\n",
    "   \n",
    "from os import listdir\n",
    "from utils import *\n",
    "from tensorflow.keras.layers import Conv2D,Input,ZeroPadding2D,BatchNormalization,Flatten,Activation,Dense,MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y8Bp9dhRcpf"
   },
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "TvMl0c2uIHpD"
   },
   "outputs": [],
   "source": [
    "image_dir=\"/home/pedrod33/Desktop/MRSI/ano1s2/AA/Brain_Tumor_Detection/archive/brain_tumor_dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THvVSvz0SORm"
   },
   "source": [
    "### Making directory for augmented images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A directory is formed using os.makedirs() function for augmented images(yes/ no). Note- custom directory is obtained in outputs folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#os.makedirs('../output/kaggle/working/augmented-images')\n",
    "#os.makedirs('../output/kaggle/working/augmented-images/yes')\n",
    "#os.makedirs('../output/kaggle/working/augmented-images/no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation of images \n",
    "**About the data:\n",
    "The dataset contains 2 folders: yes and no which contains 253 Brain MRI Images. The folder yes contains 155 Brain MRI Images that are tumorous andno contains 98 Brain MRI Images that are non-tumorous.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 17:32:58.777303: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-28 17:32:58.777335: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pedrod33): /proc/driver/nvidia/version does not exist\n",
      "2022-04-28 17:32:58.777600: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 164\n",
    "X, y = read_images()\n",
    "X = crop_images(X)\n",
    "X = resize_and_rescale(X, 164)\n",
    "X_train, y_train, X_test, y_test = split_data(X, y)\n",
    "X_train, y_train = augment_data(X_train,y_train, 164)\n",
    "\n",
    "X_train = np.array([[[[x,x,x]  for x in x2] for x2 in x1] for x1 in X_train])\n",
    "X_test = np.array([[[[x,x,x]  for x in x2] for x2 in x1] for x1 in X_test])\n",
    "\n",
    "X_train, y_train, X_val, y_val = split_data(X_train, y_train,0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCed8eg9TOl4"
   },
   "source": [
    "## Visualization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "snuuGQ3SIHsy",
    "outputId": "580bd81d-6cb3-43a0-b2ce-984953d11a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 454\n",
      "number of validation examples = 152\n",
      "number of test examples = 51\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(input_shape)) \n",
    "    model.add(ZeroPadding2D((2, 2))) \n",
    "    #Conv2D(32, (7, 7), strides = (1, 1))(X_input)\n",
    "    model.add(Conv2D(filters=32, kernel_size=4, input_shape=input_shape, strides = (1, 1)))\n",
    "    model.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
    "    model.add(Activation('leaky_relu')) \n",
    "    \n",
    "    \n",
    "    model.add(MaxPooling2D((4, 4)))\n",
    "    model.add(MaxPooling2D((4, 4))) \n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "swsrAidNIHtR",
    "outputId": "5db40543-703b-4e69-ec55-56ae8795b3ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d_1 (ZeroPaddi  (None, 168, 168, 3)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 165, 165, 32)      1568      \n",
      "                                                                 \n",
      " bn0 (BatchNormalization)    (None, 165, 165, 32)      128       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 165, 165, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 41, 41, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 10, 10, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3201      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,897\n",
      "Trainable params: 4,833\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE,3)\n",
    "model=build_model(IMG_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oM8xYsVLIHtf",
    "outputId": "20f2d4a9-3ef9-46b7-b5ea-e638b7da96d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "15/15 [==============================] - 9s 565ms/step - loss: 1.0921 - accuracy: 0.5551 - val_loss: 0.6975 - val_accuracy: 0.5658\n",
      "Epoch 2/22\n",
      "15/15 [==============================] - 8s 553ms/step - loss: 0.7843 - accuracy: 0.6256 - val_loss: 0.6803 - val_accuracy: 0.5658\n",
      "Epoch 3/22\n",
      "15/15 [==============================] - 9s 597ms/step - loss: 0.7208 - accuracy: 0.6784 - val_loss: 0.6665 - val_accuracy: 0.5658\n",
      "Epoch 4/22\n",
      "15/15 [==============================] - 9s 586ms/step - loss: 0.5348 - accuracy: 0.7599 - val_loss: 0.6541 - val_accuracy: 0.5724\n",
      "Epoch 5/22\n",
      "15/15 [==============================] - 9s 588ms/step - loss: 0.5603 - accuracy: 0.7093 - val_loss: 0.6431 - val_accuracy: 0.5921\n",
      "Epoch 6/22\n",
      "15/15 [==============================] - 9s 599ms/step - loss: 0.4964 - accuracy: 0.7687 - val_loss: 0.6367 - val_accuracy: 0.6184\n",
      "Epoch 7/22\n",
      "15/15 [==============================] - 9s 598ms/step - loss: 0.4830 - accuracy: 0.7665 - val_loss: 0.6240 - val_accuracy: 0.6579\n",
      "Epoch 8/22\n",
      "15/15 [==============================] - 9s 613ms/step - loss: 0.4799 - accuracy: 0.7753 - val_loss: 0.6233 - val_accuracy: 0.6513\n",
      "Epoch 9/22\n",
      "15/15 [==============================] - 9s 617ms/step - loss: 0.5298 - accuracy: 0.7423 - val_loss: 0.6044 - val_accuracy: 0.7039\n",
      "Epoch 10/22\n",
      "15/15 [==============================] - 9s 618ms/step - loss: 0.4498 - accuracy: 0.7930 - val_loss: 0.5997 - val_accuracy: 0.6842\n",
      "Epoch 11/22\n",
      "15/15 [==============================] - 9s 617ms/step - loss: 0.4008 - accuracy: 0.8150 - val_loss: 0.5908 - val_accuracy: 0.7105\n",
      "Epoch 12/22\n",
      "15/15 [==============================] - 9s 612ms/step - loss: 0.5512 - accuracy: 0.7533 - val_loss: 0.5774 - val_accuracy: 0.7368\n",
      "Epoch 13/22\n",
      "15/15 [==============================] - 9s 616ms/step - loss: 0.4432 - accuracy: 0.8106 - val_loss: 0.5640 - val_accuracy: 0.7368\n",
      "Epoch 14/22\n",
      "15/15 [==============================] - 10s 643ms/step - loss: 0.3589 - accuracy: 0.8370 - val_loss: 0.5587 - val_accuracy: 0.7303\n",
      "Epoch 15/22\n",
      "15/15 [==============================] - 10s 642ms/step - loss: 0.3796 - accuracy: 0.8282 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
      "Epoch 16/22\n",
      "15/15 [==============================] - 9s 611ms/step - loss: 0.4454 - accuracy: 0.8172 - val_loss: 0.5481 - val_accuracy: 0.7500\n",
      "Epoch 17/22\n",
      "15/15 [==============================] - 9s 616ms/step - loss: 0.3603 - accuracy: 0.8238 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 18/22\n",
      "15/15 [==============================] - 9s 614ms/step - loss: 0.4058 - accuracy: 0.8018 - val_loss: 0.5220 - val_accuracy: 0.7368\n",
      "Epoch 19/22\n",
      "15/15 [==============================] - 10s 638ms/step - loss: 0.4559 - accuracy: 0.7819 - val_loss: 0.5153 - val_accuracy: 0.7368\n",
      "Epoch 20/22\n",
      "15/15 [==============================] - 9s 611ms/step - loss: 0.3319 - accuracy: 0.8348 - val_loss: 0.5155 - val_accuracy: 0.7434\n",
      "Epoch 21/22\n",
      "15/15 [==============================] - 9s 612ms/step - loss: 0.3276 - accuracy: 0.8480 - val_loss: 0.5146 - val_accuracy: 0.7237\n",
      "Epoch 22/22\n",
      "15/15 [==============================] - 10s 640ms/step - loss: 0.3231 - accuracy: 0.8612 - val_loss: 0.4979 - val_accuracy: 0.7632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f526c039a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=22, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzKEvKyfTgG7"
   },
   "source": [
    "### Plotting of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fi9lvx6WIHuR",
    "outputId": "5e8a3441-85cb-44d7-c158-45989aa4a00b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 116ms/step - loss: 0.5135 - accuracy: 0.7843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5134623646736145, 0.7843137383460999]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
