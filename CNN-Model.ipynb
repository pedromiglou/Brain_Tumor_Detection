{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb7yyaPORH61"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "t4G7UWpmIHo0",
    "outputId": "c83cf3f6-6910-479c-e71b-e2725ae34c73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 18:49:08.185706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pedrod33/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-05-02 18:49:08.185728: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from os import listdir, path\n",
    "from utils import *\n",
    "from tensorflow.keras.layers import Conv2D,Input,ZeroPadding2D,BatchNormalization,Flatten,Activation,Dense,MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y8Bp9dhRcpf"
   },
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "TvMl0c2uIHpD"
   },
   "outputs": [],
   "source": [
    "image_dir=\"/home/pedrod33/Desktop/MRSI/ano1s2/AA/Brain_Tumor_Detection/archive/brain_tumor_dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THvVSvz0SORm"
   },
   "source": [
    "### Making directory for augmented images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A directory is formed using os.makedirs() function for augmented images(yes/ no). Note- custom directory is obtained in outputs folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists('output/kaggle/working/augmented-images'):\n",
    "    os.makedirs('output/kaggle/working/augmented-images')\n",
    "if not path.exists('output/kaggle/working/augmented-images/yes'):\n",
    "    os.makedirs('output/kaggle/working/augmented-images/yes')\n",
    "if not path.exists('output/kaggle/working/augmented-images/no'):\n",
    "    os.makedirs('output/kaggle/working/augmented-images/no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation of images \n",
    "**About the data:\n",
    "The dataset contains 2 folders: yes and no which contains 253 Brain MRI Images. The folder yes contains 155 Brain MRI Images that are tumorous andno contains 98 Brain MRI Images that are non-tumorous.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 18:49:10.309799: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-02 18:49:10.309886: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pedrod33): /proc/driver/nvidia/version does not exist\n",
      "2022-05-02 18:49:10.310657: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/pedrod33/Desktop/MRSI/ano1s2/AA/Brain_Tumor_Detection/utils.py:104: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(new_images), np.array(new_labels)\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "X, y = read_images()\n",
    "X = crop_images(X)\n",
    "aug_X, aug_y = augment_data(X,y, IMG_SIZE=IMG_SIZE)\n",
    "aug_X = resize_and_rescale(aug_X, IMG_SIZE)\n",
    "X = resize_and_rescale(X, IMG_SIZE)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_and_shuffle(aug_X, aug_y)\n",
    "\n",
    "X_train = np.array([[[[x,x,x]  for x in x2] for x2 in x1] for x1 in X_train])\n",
    "X_val = np.array([[[[x,x,x]  for x in x2] for x2 in x1] for x1 in X_val])\n",
    "X_test = np.array([[[[x,x,x]  for x in x2] for x2 in x1] for x1 in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCed8eg9TOl4"
   },
   "source": [
    "## Visualization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "snuuGQ3SIHsy",
    "outputId": "580bd81d-6cb3-43a0-b2ce-984953d11a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 303\n",
      "number of test examples = 253\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    #removed normalization from last 2 conv layers because values were becoming too similar resulting in overfit\n",
    "    model = Sequential()\n",
    "    model.add(Input(input_shape)) \n",
    "    model.add(ZeroPadding2D((2, 2))) \n",
    "    #Conv2D(32, (7, 7), strides = (1, 1))(X_input)\n",
    "    model.add(Activation('relu')) \n",
    "\n",
    "    model.add(Conv2D(filters=24, kernel_size=4, input_shape=input_shape, strides = (1, 1)))\n",
    "    model.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
    "    model.add(MaxPooling2D((4,4), strides = (4, 4),padding=\"valid\"))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Conv2D(filters=36, kernel_size=4, input_shape=input_shape, strides = (1, 1)))\n",
    "    model.add(MaxPooling2D((4,4), strides = (4,4),padding=\"valid\"))\n",
    "    model.add(Dropout(.3))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=4, input_shape=input_shape, strides = (1, 1)))\n",
    "    model.add(MaxPooling2D((4,4), strides = (4,4),padding=\"valid\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    '''\n",
    "    model.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"leaky_relu\",kernel_initializer=\"he_uniform\",padding=\"same\",input_shape=(IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"valid\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3),activation=\"leaky_relu\",kernel_initializer=\"he_uniform\",padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(4,4),strides=4, padding=\"valid\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(filters=128,kernel_size=(3,3),activation=\"leaky_relu\",kernel_initializer=\"he_uniform\",padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128,activation=\"leaky_relu\",kernel_initializer=\"he_uniform\"))\n",
    "    model.add(Dense(units=1,activation=\"sigmoid\"))# compile the modelmodel2.compile(optimizer=”adam”,loss=”binary_crossentropy”,metrics=[“accuracy”])\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "swsrAidNIHtR",
    "outputId": "5db40543-703b-4e69-ec55-56ae8795b3ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d (ZeroPadding  (None, 228, 228, 3)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation (Activation)     (None, 228, 228, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 225, 225, 24)      1176      \n",
      "                                                                 \n",
      " bn0 (BatchNormalization)    (None, 225, 225, 24)      96        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 56, 56, 24)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 56, 56, 24)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 53, 53, 36)        13860     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 36)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 13, 36)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,317\n",
      "Trainable params: 52,269\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE,3)\n",
    "model=build_model(IMG_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oM8xYsVLIHtf",
    "outputId": "20f2d4a9-3ef9-46b7-b5ea-e638b7da96d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.9214 - accuracy: 0.6271 - val_loss: 0.6751 - val_accuracy: 0.5644\n",
      "Epoch 2/22\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6475 - accuracy: 0.6766 - val_loss: 0.6615 - val_accuracy: 0.7426\n",
      "Epoch 3/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5540 - accuracy: 0.7228 - val_loss: 0.6620 - val_accuracy: 0.5644\n",
      "Epoch 4/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4949 - accuracy: 0.7723 - val_loss: 0.6452 - val_accuracy: 0.7129\n",
      "Epoch 5/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4571 - accuracy: 0.8020 - val_loss: 0.6260 - val_accuracy: 0.5842\n",
      "Epoch 6/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4308 - accuracy: 0.8251 - val_loss: 0.6153 - val_accuracy: 0.6634\n",
      "Epoch 7/22\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3764 - accuracy: 0.8581 - val_loss: 0.5987 - val_accuracy: 0.7327\n",
      "Epoch 8/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3486 - accuracy: 0.8779 - val_loss: 0.5853 - val_accuracy: 0.7822\n",
      "Epoch 9/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3495 - accuracy: 0.8515 - val_loss: 0.5839 - val_accuracy: 0.6139\n",
      "Epoch 10/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3218 - accuracy: 0.8713 - val_loss: 0.5656 - val_accuracy: 0.7129\n",
      "Epoch 11/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2946 - accuracy: 0.8911 - val_loss: 0.5530 - val_accuracy: 0.6832\n",
      "Epoch 12/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2331 - accuracy: 0.9043 - val_loss: 0.5695 - val_accuracy: 0.6337\n",
      "Epoch 13/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2338 - accuracy: 0.9208 - val_loss: 0.5341 - val_accuracy: 0.7228\n",
      "Epoch 14/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2421 - accuracy: 0.9043 - val_loss: 0.5422 - val_accuracy: 0.6733\n",
      "Epoch 15/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.1924 - accuracy: 0.9307 - val_loss: 0.5982 - val_accuracy: 0.6337\n",
      "Epoch 16/22\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2100 - accuracy: 0.9175 - val_loss: 0.5611 - val_accuracy: 0.6238\n",
      "Epoch 17/22\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.1685 - accuracy: 0.9472 - val_loss: 0.5034 - val_accuracy: 0.7822\n",
      "Epoch 18/22\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1492 - accuracy: 0.9604 - val_loss: 0.5488 - val_accuracy: 0.7030\n",
      "Epoch 19/22\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1644 - accuracy: 0.9373 - val_loss: 0.5764 - val_accuracy: 0.6832\n",
      "Epoch 20/22\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2421 - accuracy: 0.8977 - val_loss: 0.6033 - val_accuracy: 0.6337\n",
      "Epoch 21/22\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2109 - accuracy: 0.9142 - val_loss: 0.4552 - val_accuracy: 0.8119\n",
      "Epoch 22/22\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1336 - accuracy: 0.9505 - val_loss: 0.5102 - val_accuracy: 0.7525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f49481bf280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=22, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzKEvKyfTgG7"
   },
   "source": [
    "### Plotting of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fi9lvx6WIHuR",
    "outputId": "5e8a3441-85cb-44d7-c158-45989aa4a00b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 230ms/step - loss: 0.3617 - accuracy: 0.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36174365878105164, 0.8853754997253418]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
